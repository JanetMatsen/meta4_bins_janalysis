#!/bin/bash

# make it stop if there is a problem. 
# actually this doesn't work b/c conda throws errors
# set -eux

# test that worked earlier for one particular mummer pair: 
# python support_files/mummer_two_bins.py /work/meta4_bins/data/bins/dave/bins/elviz-contigs-1056187.Methylobacter-1.fasta /work/meta4_bins/data/bins/fauzi/bins/Methylobacter-123.fasta ./toy

# Activate my virtualenv for packages like BioPython and envoy.  
# More info about virtualenv at: janalysis/virtualenv
source activate m4_janalysis

# prepare the available bins. 
rm ./support_files/available_bins.csv
python ./support_files/survey_available_bins.py

# prepare the list of .fasta files for each job's query sequence
# makes files in ./support_files/jobs/ with a list of bin names. 
python ./support_files/break_apart_bin_jobs.py

## test run:
#python ./support_files/mummer_some_pairs.py "./support_files/jobs/13--2_rows" "./test" 'True'

# do all the runs
# & supresses output so they can all run at once. 
for job in ./support_files/jobs/job*; do 
    # used to call `sh $job &` but this threw an error, likely due to conda python
    # it doens't throw that error when run this way, so stick with it. 
    $job &
done
# wait will wait until all the background processes are done
wait

# once all the jobs are done, aggregate the MUMmer .tsv files into a summary tsv. 
# Note: as of 160613, this final .py script was run by hand. 
python ./support_files/aggregate_mummer_results.py 
